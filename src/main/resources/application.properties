spring.application.name=kotlin-crud-operations

# Server Configuration
server.port=8081

# Allow bean definition overriding
spring.main.allow-bean-definition-overriding=true

# MySQL Configuration
spring.datasource.url=jdbc:mysql://${MYSQL_HOST:localhost}:3306/kotlin_db?createDatabaseIfNotExist=true&useSSL=false&allowPublicKeyRetrieval=true&serverTimezone=UTC
spring.datasource.username=${MYSQL_USER:root}
spring.datasource.password=${MYSQL_PASSWORD:root}
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver

# Connection pool settings
spring.datasource.hikari.connection-timeout=30000
spring.datasource.hikari.maximum-pool-size=5
spring.datasource.hikari.minimum-idle=1
spring.datasource.hikari.connection-init-sql=SELECT 1
spring.datasource.hikari.leak-detection-threshold=2000

# JPA/Hibernate
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=true
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL8Dialect
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.hibernate.naming.physical-strategy=org.hibernate.boot.model.naming.CamelCaseToUnderscoresNamingStrategy

# Flyway Configuration (temporarily disabled for testing)
spring.flyway.enabled=false
# spring.flyway.baseline-on-migrate=true
# spring.flyway.locations=classpath:db/migration

# Kafka Configuration
spring.kafka.bootstrap-servers=${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
spring.kafka.consumer.group-id=user-service-group
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=*
spring.kafka.consumer.properties.spring.json.use.type.headers=false
spring.kafka.consumer.properties.spring.json.value.default.type=com.kotlin_learning.dto.UserEvent
spring.kafka.consumer.properties.request.timeout.ms=30000
spring.kafka.consumer.properties.retry.backoff.ms=1000

# Producer Configuration
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
spring.kafka.producer.retries=3
spring.kafka.producer.properties.retry.backoff.ms=1000

# Admin Configuration
spring.kafka.admin.fail-fast=false
spring.kafka.admin.properties.bootstrap.servers=${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
spring.kafka.admin.properties.request.timeout.ms=30000
spring.kafka.admin.properties.retries=5
spring.kafka.admin.properties.retry.backoff.ms=1000

# Disable auto topic creation in the application since we're managing it in Docker
spring.kafka.admin.auto-create=false

# Redis Configuration
spring.redis.host=${SPRING_REDIS_HOST:localhost}
spring.redis.port=${SPRING_REDIS_PORT:6379}
spring.redis.timeout=5000

# Cache Configuration
spring.cache.type=redis
spring.cache.redis.time-to-live=3600000  # 1 hour in milliseconds
spring.cache.redis.cache-null-values=false
spring.cache.redis.key-prefix=app_cache:
spring.cache.redis.use-key-prefix=true

# Actuator for Health Checks
management.endpoint.health.show-details=always
management.endpoints.web.exposure.include=health,info,metrics
management.health.redis.enabled=true

# OpenAPI Configuration
springdoc.api-docs.path=/api-docs
springdoc.swagger-ui.path=/swagger-ui.html
springdoc.swagger-ui.operationsSorter=method

